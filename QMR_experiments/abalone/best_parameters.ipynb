{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"best_parameters.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZCPBrmrNlTgk","executionInfo":{"status":"ok","timestamp":1611624130906,"user_tz":300,"elapsed":3287,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["import pickle\n","import gzip\n","import numpy as np\n","import scipy\n","import pandas as pd\n","import keras\n","import keras.layers as layers\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from keras.layers import Input, LSTM, Dense, Lambda, Conv1D, Conv2D, AveragePooling2D, AveragePooling1D, Flatten, MaxPooling2D, MaxPooling1D, Dropout\n","from keras.models import Model\n","from keras.models import Sequential\n","from keras.utils import Sequence\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n","from keras.layers.normalization import BatchNormalization\n","from keras.optimizers import RMSprop\n","from keras.applications import imagenet_utils\n","from keras import backend as K\n","from time import time\n","from keras import losses\n","from sklearn.metrics import  roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score, mean_absolute_error\n","import glob\n","from PIL import Image\n","import h5py\n","import random\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.decomposition import PCA, KernelPCA\n","from sklearn.metrics import confusion_matrix\n","from sklearn import svm\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import roc_auc_score\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import sklearn.gaussian_process as gp\n","import pandas as pd\n","import pickle\n","from joblib import dump, load\n","from sklearn.utils import shuffle\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.model_selection import KFold\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dBqLDYY-KpF","executionInfo":{"status":"ok","timestamp":1611624135203,"user_tz":300,"elapsed":7551,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"c98fc5b6-6c66-48cf-9e16-4bcc18ee2abb"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","!pip install silence_tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting silence_tensorflow\n","  Downloading https://files.pythonhosted.org/packages/96/d7/076b21d0e79cfc8a085f623e6577b754c50a42cfbcce51d77d0d2206988c/silence_tensorflow-1.1.1.tar.gz\n","Building wheels for collected packages: silence-tensorflow\n","  Building wheel for silence-tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for silence-tensorflow: filename=silence_tensorflow-1.1.1-cp36-none-any.whl size=3743 sha256=253b29c8d032b1af090553adefdb948a6fbf88af6d7bb183f6e1c1cb09c91b17\n","  Stored in directory: /root/.cache/pip/wheels/51/0b/35/cf3020764bee61daa81fa249df3a448e3806344a087fc12292\n","Successfully built silence-tensorflow\n","Installing collected packages: silence-tensorflow\n","Successfully installed silence-tensorflow-1.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SIgN8hut-NIv","executionInfo":{"status":"ok","timestamp":1611624135208,"user_tz":300,"elapsed":7547,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["from silence_tensorflow import silence_tensorflow\n","silence_tensorflow()\n","import tensorflow as tf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gxfiLob40IW","executionInfo":{"status":"ok","timestamp":1611624153255,"user_tz":300,"elapsed":25583,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"dc62097e-9e74-4443-8317-623b8c096ce7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDHN4AmAmDo4","executionInfo":{"status":"ok","timestamp":1611624153258,"user_tz":300,"elapsed":24834,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"8e1e1a6f-0f1b-4285-c6f3-2bce569553d6"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Tue Jan 26 01:22:32 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bl08DctzrSxS","executionInfo":{"status":"ok","timestamp":1611624159713,"user_tz":300,"elapsed":6442,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"9b34b0ba-9b27-446d-8e7f-ae38ede52b3b"},"source":["try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","if IN_COLAB:\n","    !rm -R qmc qmc1\n","    !git clone https://github.com/fagonzalezo/qmc.git\n","    !mv qmc qmc1\n","    !mv qmc1/qmc .\n","else:\n","    import sys\n","    sys.path.insert(0, \"../\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'qmc': No such file or directory\n","rm: cannot remove 'qmc1': No such file or directory\n","Cloning into 'qmc'...\n","remote: Enumerating objects: 215, done.\u001b[K\n","remote: Total 215 (delta 0), reused 0 (delta 0), pack-reused 215\n","Receiving objects: 100% (215/215), 17.06 MiB | 5.59 MiB/s, done.\n","Resolving deltas: 100% (91/91), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cvBeHDQhrVAJ","executionInfo":{"status":"ok","timestamp":1611624159715,"user_tz":300,"elapsed":6438,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["import qmc.tf.layers as layers\n","import qmc.tf.models as models"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHZgRRT07ZmH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611628127030,"user_tz":300,"elapsed":3973134,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"04c705a3-5a68-4bfe-a136-eab6567833ff"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  17.11949555807705 \n","    gamma_opt =  0.007032918605122784 \n","    learning_rate_opt =  4.303764234909502e-05 \n","    alpha_opt =  0.3304390103289042 \n","    dim_x_opt =  520 \n","    num_eig_opt =  32\n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["---------------------------------------- 1\n","250/250 [==============================] - 2s 926us/step\n","------------MAE = 0.2329241422725842\n","---------------------------------------- 2\n","250/250 [==============================] - 0s 914us/step\n","------------MAE = 0.24362606232294617\n","---------------------------------------- 3\n","250/250 [==============================] - 0s 911us/step\n","------------MAE = 0.23197985520931697\n","---------------------------------------- 4\n","250/250 [==============================] - 0s 932us/step\n","------------MAE = 0.2360717658168083\n","---------------------------------------- 5\n","250/250 [==============================] - 0s 918us/step\n","------------MAE = 0.2332389046270066\n","---------------------------------------- 6\n","250/250 [==============================] - 0s 913us/step\n","------------MAE = 0.2360717658168083\n","---------------------------------------- 7\n","250/250 [==============================] - 0s 902us/step\n","------------MAE = 0.22505508341202393\n","---------------------------------------- 8\n","250/250 [==============================] - 0s 946us/step\n","------------MAE = 0.2354422411079635\n","---------------------------------------- 9\n","250/250 [==============================] - 0s 900us/step\n","------------MAE = 0.24551463644948066\n","---------------------------------------- 10\n","250/250 [==============================] - 0s 949us/step\n","------------MAE = 0.26786276361347183\n","---------------------------------------- 11\n","250/250 [==============================] - 0s 963us/step\n","------------MAE = 0.23418319169027385\n","---------------------------------------- 12\n","250/250 [==============================] - 0s 938us/step\n","------------MAE = 0.2363865281712307\n","---------------------------------------- 13\n","250/250 [==============================] - 0s 949us/step\n","------------MAE = 0.22851746931067043\n","---------------------------------------- 14\n","250/250 [==============================] - 0s 931us/step\n","------------MAE = 0.23953415171545483\n","---------------------------------------- 15\n","250/250 [==============================] - 0s 959us/step\n","------------MAE = 0.24268177525967893\n","---------------------------------------- 16\n","250/250 [==============================] - 0s 904us/step\n","------------MAE = 0.22820270695624803\n","---------------------------------------- 17\n","250/250 [==============================] - 0s 922us/step\n","------------MAE = 0.2326093799181618\n","---------------------------------------- 18\n","250/250 [==============================] - 0s 976us/step\n","------------MAE = 0.24079320113314448\n","---------------------------------------- 19\n","250/250 [==============================] - 0s 908us/step\n","------------MAE = 0.23953415171545483\n","---------------------------------------- 20\n","250/250 [==============================] - 0s 891us/step\n","------------MAE = 0.24268177525967893\n","0.2376455775889204\n","0.008752431245295353\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8C9lKDsq8Mw9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611635935635,"user_tz":300,"elapsed":11778549,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"aaa77d6e-eb71-4673-9a3a-0fcd64dd5f31"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  17.063701755341143 \n","    gamma_opt =  0.04331796027334034 \n","    learning_rate_opt =  0.000538349255020578 \n","    alpha_opt =  0.6829444476677953 \n","    dim_x_opt =  852 \n","    num_eig_opt =  53\n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["---------------------------------------- 1\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2360717658168083\n","---------------------------------------- 2\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.249606547056972\n","---------------------------------------- 3\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2357570034623859\n","---------------------------------------- 4\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2360717658168083\n","---------------------------------------- 5\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2382751022977652\n","---------------------------------------- 6\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.24110796348756688\n","---------------------------------------- 7\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2326093799181618\n","---------------------------------------- 8\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2382751022977652\n","---------------------------------------- 9\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.23921938936103243\n","---------------------------------------- 10\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.24929178470254956\n","---------------------------------------- 11\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.23512747875354106\n","---------------------------------------- 12\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.23386842933585142\n","---------------------------------------- 13\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.23701605288007555\n","---------------------------------------- 14\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2363865281712307\n","---------------------------------------- 15\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.2521246458923513\n","---------------------------------------- 16\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.23418319169027385\n","---------------------------------------- 17\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.24331129996852377\n","---------------------------------------- 18\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.24047843877872208\n","---------------------------------------- 19\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.23355366698142901\n","---------------------------------------- 20\n","250/250 [==============================] - 1s 2ms/step\n","------------MAE = 0.24079320113314448\n","0.23915643689014798\n","0.0054460254967282785\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DZa5QYrz8Not","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611639914556,"user_tz":300,"elapsed":15754815,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"1a01bb68-8c14-44bd-ee0b-7292c418ef84"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  3.37146281630272 \n","    gamma_opt =  0.05080303770732676 \n","    learning_rate_opt =  0.0004130846608408064 \n","    alpha_opt =  0.22621278830805103 \n","    dim_x_opt =  646 \n","    num_eig_opt =  323\n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["---------------------------------------- 1\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23386842933585142\n","---------------------------------------- 2\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.2502360717658168\n","---------------------------------------- 3\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.2332389046270066\n","---------------------------------------- 4\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.2514951211835065\n","---------------------------------------- 5\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.22914699401951527\n","---------------------------------------- 6\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23040604343720492\n","---------------------------------------- 7\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.22977651872836008\n","---------------------------------------- 8\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23984891406987724\n","---------------------------------------- 9\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.24677368586717027\n","---------------------------------------- 10\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.2382751022977652\n","---------------------------------------- 11\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23386842933585142\n","---------------------------------------- 12\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23229461756373937\n","---------------------------------------- 13\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23072080579162732\n","---------------------------------------- 14\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23449795404469626\n","---------------------------------------- 15\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23449795404469626\n","---------------------------------------- 16\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23072080579162732\n","---------------------------------------- 17\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23135033050047216\n","---------------------------------------- 18\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.24299653761410137\n","---------------------------------------- 19\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23135033050047216\n","---------------------------------------- 20\n","250/250 [==============================] - 0s 1ms/step\n","------------MAE = 0.23481271639911866\n","0.2360088133459238\n","0.006633649290434746\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j0AvKBDY8Nre"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B72ds1Dq8NuE"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5Z0zHnO8Nw0"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVD6d1Eg8Nzb"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hoq95Kjn8N10"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKzNXUS38N4h"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dARMtUtZ8N6z"},"source":["BIG_MAE=[]\n","for i in range(20):\n","    print('----------------------------------------',i+1)\n","    number = str(i+1)\n","    train_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_train_5.'\n","    test_path = '/content/drive/My Drive/Colab_Notebooks/ICML2021/abalone/data/abalone_test_5.'\n","    \n","    data = pd.read_csv(train_path+number, header = None, sep = ' ')\n","    X = data.to_numpy()\n","    y = X[:,-1]\n","    X = X[:,0:-1]\n","\n","    y = (y-1)/4\n","    y = np.float64(y)\n","    y = y.reshape((1000,1))\n","    X = np.float64(X)\n","\n","    scaler = preprocessing.StandardScaler().fit(X)\n","    X = scaler.transform(X)\n","    X, y = shuffle(X, y, random_state=0)\n","    MAE_opt = 100\n","    dim_y = 5\n","\n","    beta_opt =  \n","    gamma_opt =  \n","    learning_rate_opt =   \n","    alpha_opt =  \n","    dim_x_opt =  \n","    num_eig_opt =  \n","\n","    X_train = X\n","    y_train = y\n","\n","    X_test = pd.read_csv(test_path+number, header = None, sep = ' ')\n","    X_test = X_test.to_numpy()\n","    X_test = np.float64(X_test)\n","    y_test = X_test[:,-1]\n","    X_test = X_test[:,0:-1]\n","    X_test = scaler.transform(X_test)\n","    y_test = (y_test-1)/4\n","    y_test = np.float64(y_test)\n","    y_test = y_test.reshape((3177,1))\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta_opt)\n","    fm_x = layers.QFeatureMapRFF(10, dim=dim_x_opt, gamma=gamma_opt, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=10, dim_x=dim_x_opt, num_eig=num_eig_opt, dim_y=dim_y, gamma=gamma_opt, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x_opt, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_opt)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha_opt * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=0,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=100, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","    print('------------MAE =', mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","    BIG_MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","print(np.mean(BIG_MAE))\n","print(np.std(BIG_MAE))"],"execution_count":null,"outputs":[]}]}