{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copia de Wisconsin_Cross_Validation_Random_search_QMR_DR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZCPBrmrNlTgk","executionInfo":{"status":"ok","timestamp":1609211872874,"user_tz":300,"elapsed":3146,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["import pickle\n","import gzip\n","import numpy as np\n","import scipy\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","import keras.layers as layers\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from keras.layers import Input, LSTM, Dense, Lambda, Conv1D, Conv2D, AveragePooling2D, AveragePooling1D, Flatten, MaxPooling2D, MaxPooling1D, Dropout\n","from keras.models import Model\n","from keras.models import Sequential\n","from keras.utils import Sequence\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n","from keras.layers.normalization import BatchNormalization\n","from keras.optimizers import RMSprop\n","from keras.applications import imagenet_utils\n","from keras import backend as K\n","from time import time\n","from keras import losses\n","from sklearn.metrics import  roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score, mean_absolute_error\n","import glob\n","from PIL import Image\n","import h5py\n","import random\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.decomposition import PCA, KernelPCA\n","from sklearn.metrics import confusion_matrix\n","from sklearn import svm\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import roc_auc_score\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import sklearn.gaussian_process as gp\n","import pandas as pd\n","import pickle\n","from joblib import dump, load\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gxfiLob40IW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211902195,"user_tz":300,"elapsed":32448,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"35c9c373-b081-4d1b-b9fe-1feaa54b57a2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nDHN4AmAmDo4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211902196,"user_tz":300,"elapsed":32441,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"851c220b-1198-46eb-b729-72da8009c539"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Tue Dec 29 03:18:21 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bl08DctzrSxS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211908705,"user_tz":300,"elapsed":2963,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"99dc8799-f8e2-40c3-8efd-2782c3097626"},"source":["try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","if IN_COLAB:\n","    !rm -R qmc qmc1\n","    !git clone https://github.com/fagonzalezo/qmc.git\n","    !mv qmc qmc1\n","    !mv qmc1/qmc .\n","else:\n","    import sys\n","    sys.path.insert(0, \"../\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'qmc': No such file or directory\n","rm: cannot remove 'qmc1': No such file or directory\n","Cloning into 'qmc'...\n","remote: Enumerating objects: 215, done.\u001b[K\n","remote: Total 215 (delta 0), reused 0 (delta 0), pack-reused 215\u001b[K\n","Receiving objects: 100% (215/215), 17.06 MiB | 26.19 MiB/s, done.\n","Resolving deltas: 100% (91/91), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cvBeHDQhrVAJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211908706,"user_tz":300,"elapsed":639,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"46746a10-5d5a-4831-f72c-fa312e2f6250"},"source":["import qmc.tf.layers as layers\n","import qmc.tf.models as models"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/typeguard/__init__.py:804: UserWarning: no type annotations present -- not typechecking qmc.tf.layers.CrossProduct.__init__\n","  warn('no type annotations present -- not typechecking {}'.format(function_name(func)))\n","/usr/local/lib/python3.6/dist-packages/typeguard/__init__.py:804: UserWarning: no type annotations present -- not typechecking qmc.tf.layers.DensityMatrix2Dist.__init__\n","  warn('no type annotations present -- not typechecking {}'.format(function_name(func)))\n","/usr/local/lib/python3.6/dist-packages/typeguard/__init__.py:804: UserWarning: no type annotations present -- not typechecking qmc.tf.layers.DensityMatrixRegression.__init__\n","  warn('no type annotations present -- not typechecking {}'.format(function_name(func)))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6qjNZ_KarWOp","executionInfo":{"status":"ok","timestamp":1609211910449,"user_tz":300,"elapsed":687,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["import matplotlib.pyplot as plt\n","plt.style.use('ggplot')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftyweZXOsGyd","executionInfo":{"status":"ok","timestamp":1609211911976,"user_tz":300,"elapsed":672,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["from sklearn.utils import shuffle"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7OL0ubgisY5","executionInfo":{"status":"ok","timestamp":1609211968410,"user_tz":300,"elapsed":2528,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["import pandas as pd\n","\n","data = pd.read_csv('/content/drive/My Drive/Colab_Notebooks/ICML2021/wisconsin/data/wpbc_all', header = None, sep = ' ')\n","#X = np.loadtxt('/content/drive/My Drive/Colab_Notebooks/qmr_losses_experiments/wisconsin.data')\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"RsSHUrwJoTsM","executionInfo":{"status":"ok","timestamp":1609211974500,"user_tz":300,"elapsed":674,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"949ab7dc-0555-46c6-c205-96c56e9cff1d"},"source":["data"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>16.13</td>\n","      <td>20.68</td>\n","      <td>108.10</td>\n","      <td>798.8</td>\n","      <td>0.11700</td>\n","      <td>0.2022</td>\n","      <td>0.17220</td>\n","      <td>0.10280</td>\n","      <td>0.2164</td>\n","      <td>0.07356</td>\n","      <td>0.5692</td>\n","      <td>1.0730</td>\n","      <td>3.854</td>\n","      <td>54.18</td>\n","      <td>0.00703</td>\n","      <td>0.02501</td>\n","      <td>0.03188</td>\n","      <td>0.01297</td>\n","      <td>0.01689</td>\n","      <td>0.00414</td>\n","      <td>20.96</td>\n","      <td>31.48</td>\n","      <td>136.8</td>\n","      <td>1315.0</td>\n","      <td>0.1789</td>\n","      <td>0.4233</td>\n","      <td>0.4784</td>\n","      <td>0.2073</td>\n","      <td>0.3706</td>\n","      <td>0.11420</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>15.34</td>\n","      <td>14.26</td>\n","      <td>102.50</td>\n","      <td>704.4</td>\n","      <td>0.10730</td>\n","      <td>0.2135</td>\n","      <td>0.20770</td>\n","      <td>0.09756</td>\n","      <td>0.2521</td>\n","      <td>0.07032</td>\n","      <td>0.4388</td>\n","      <td>0.7096</td>\n","      <td>3.384</td>\n","      <td>44.91</td>\n","      <td>0.00679</td>\n","      <td>0.05328</td>\n","      <td>0.06446</td>\n","      <td>0.02252</td>\n","      <td>0.03672</td>\n","      <td>0.00439</td>\n","      <td>18.07</td>\n","      <td>19.08</td>\n","      <td>125.1</td>\n","      <td>980.9</td>\n","      <td>0.1390</td>\n","      <td>0.5954</td>\n","      <td>0.6305</td>\n","      <td>0.2393</td>\n","      <td>0.4667</td>\n","      <td>0.09946</td>\n","      <td>1.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>21.16</td>\n","      <td>23.04</td>\n","      <td>137.20</td>\n","      <td>1404.0</td>\n","      <td>0.09428</td>\n","      <td>0.1022</td>\n","      <td>0.10970</td>\n","      <td>0.08632</td>\n","      <td>0.1769</td>\n","      <td>0.05278</td>\n","      <td>0.6917</td>\n","      <td>1.1270</td>\n","      <td>4.303</td>\n","      <td>93.99</td>\n","      <td>0.00473</td>\n","      <td>0.01259</td>\n","      <td>0.01715</td>\n","      <td>0.01038</td>\n","      <td>0.01083</td>\n","      <td>0.00199</td>\n","      <td>29.17</td>\n","      <td>35.59</td>\n","      <td>188.0</td>\n","      <td>2615.0</td>\n","      <td>0.1401</td>\n","      <td>0.2600</td>\n","      <td>0.3155</td>\n","      <td>0.2009</td>\n","      <td>0.2822</td>\n","      <td>0.07526</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>19.07</td>\n","      <td>24.81</td>\n","      <td>128.30</td>\n","      <td>1104.0</td>\n","      <td>0.09081</td>\n","      <td>0.2190</td>\n","      <td>0.21070</td>\n","      <td>0.09961</td>\n","      <td>0.2310</td>\n","      <td>0.06343</td>\n","      <td>0.9811</td>\n","      <td>1.6660</td>\n","      <td>8.830</td>\n","      <td>104.90</td>\n","      <td>0.00655</td>\n","      <td>0.10060</td>\n","      <td>0.09723</td>\n","      <td>0.02638</td>\n","      <td>0.05333</td>\n","      <td>0.00765</td>\n","      <td>24.09</td>\n","      <td>33.17</td>\n","      <td>177.4</td>\n","      <td>1651.0</td>\n","      <td>0.1247</td>\n","      <td>0.7444</td>\n","      <td>0.7242</td>\n","      <td>0.2493</td>\n","      <td>0.4670</td>\n","      <td>0.10380</td>\n","      <td>2.3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>18.65</td>\n","      <td>17.60</td>\n","      <td>123.70</td>\n","      <td>1076.0</td>\n","      <td>0.10990</td>\n","      <td>0.1686</td>\n","      <td>0.19740</td>\n","      <td>0.10090</td>\n","      <td>0.1907</td>\n","      <td>0.06049</td>\n","      <td>0.6289</td>\n","      <td>0.6633</td>\n","      <td>4.293</td>\n","      <td>71.56</td>\n","      <td>0.00629</td>\n","      <td>0.03994</td>\n","      <td>0.05554</td>\n","      <td>0.01695</td>\n","      <td>0.02428</td>\n","      <td>0.00353</td>\n","      <td>22.82</td>\n","      <td>21.32</td>\n","      <td>150.6</td>\n","      <td>1567.0</td>\n","      <td>0.1679</td>\n","      <td>0.5090</td>\n","      <td>0.7345</td>\n","      <td>0.2378</td>\n","      <td>0.3799</td>\n","      <td>0.09185</td>\n","      <td>1.8</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>189</th>\n","      <td>0.0</td>\n","      <td>15.78</td>\n","      <td>17.89</td>\n","      <td>103.60</td>\n","      <td>781.0</td>\n","      <td>0.09710</td>\n","      <td>0.1292</td>\n","      <td>0.09954</td>\n","      <td>0.06606</td>\n","      <td>0.1842</td>\n","      <td>0.06082</td>\n","      <td>0.5058</td>\n","      <td>0.9849</td>\n","      <td>3.564</td>\n","      <td>54.16</td>\n","      <td>0.00577</td>\n","      <td>0.04061</td>\n","      <td>0.02791</td>\n","      <td>0.01282</td>\n","      <td>0.02008</td>\n","      <td>0.00414</td>\n","      <td>20.42</td>\n","      <td>27.28</td>\n","      <td>136.5</td>\n","      <td>1299.0</td>\n","      <td>0.1396</td>\n","      <td>0.5609</td>\n","      <td>0.3965</td>\n","      <td>0.1810</td>\n","      <td>0.3792</td>\n","      <td>0.10480</td>\n","      <td>1.4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>190</th>\n","      <td>0.0</td>\n","      <td>14.68</td>\n","      <td>20.13</td>\n","      <td>94.74</td>\n","      <td>684.5</td>\n","      <td>0.09867</td>\n","      <td>0.0720</td>\n","      <td>0.07395</td>\n","      <td>0.05259</td>\n","      <td>0.1586</td>\n","      <td>0.05922</td>\n","      <td>0.4727</td>\n","      <td>1.2400</td>\n","      <td>3.195</td>\n","      <td>45.40</td>\n","      <td>0.00572</td>\n","      <td>0.01162</td>\n","      <td>0.01998</td>\n","      <td>0.01109</td>\n","      <td>0.01410</td>\n","      <td>0.00209</td>\n","      <td>19.07</td>\n","      <td>30.88</td>\n","      <td>123.4</td>\n","      <td>1138.0</td>\n","      <td>0.1464</td>\n","      <td>0.1871</td>\n","      <td>0.2914</td>\n","      <td>0.1609</td>\n","      <td>0.3029</td>\n","      <td>0.08216</td>\n","      <td>1.1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>2.0</td>\n","      <td>11.84</td>\n","      <td>18.70</td>\n","      <td>77.93</td>\n","      <td>440.6</td>\n","      <td>0.11090</td>\n","      <td>0.1516</td>\n","      <td>0.12180</td>\n","      <td>0.05182</td>\n","      <td>0.2301</td>\n","      <td>0.07799</td>\n","      <td>0.4825</td>\n","      <td>1.0300</td>\n","      <td>3.475</td>\n","      <td>41.00</td>\n","      <td>0.00555</td>\n","      <td>0.03414</td>\n","      <td>0.04205</td>\n","      <td>0.01044</td>\n","      <td>0.02273</td>\n","      <td>0.00567</td>\n","      <td>16.82</td>\n","      <td>28.12</td>\n","      <td>119.4</td>\n","      <td>888.7</td>\n","      <td>0.1637</td>\n","      <td>0.5775</td>\n","      <td>0.6956</td>\n","      <td>0.1546</td>\n","      <td>0.4761</td>\n","      <td>0.14020</td>\n","      <td>3.0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>0.0</td>\n","      <td>13.11</td>\n","      <td>15.56</td>\n","      <td>87.21</td>\n","      <td>530.2</td>\n","      <td>0.13980</td>\n","      <td>0.1765</td>\n","      <td>0.20710</td>\n","      <td>0.09601</td>\n","      <td>0.1925</td>\n","      <td>0.07692</td>\n","      <td>0.3908</td>\n","      <td>0.9238</td>\n","      <td>2.410</td>\n","      <td>34.66</td>\n","      <td>0.00716</td>\n","      <td>0.02912</td>\n","      <td>0.05473</td>\n","      <td>0.01388</td>\n","      <td>0.01547</td>\n","      <td>0.00710</td>\n","      <td>16.31</td>\n","      <td>22.40</td>\n","      <td>106.4</td>\n","      <td>827.2</td>\n","      <td>0.1862</td>\n","      <td>0.4099</td>\n","      <td>0.6376</td>\n","      <td>0.1986</td>\n","      <td>0.3147</td>\n","      <td>0.14050</td>\n","      <td>1.5</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>0.0</td>\n","      <td>16.16</td>\n","      <td>21.54</td>\n","      <td>106.20</td>\n","      <td>809.8</td>\n","      <td>0.10080</td>\n","      <td>0.1284</td>\n","      <td>0.10430</td>\n","      <td>0.05613</td>\n","      <td>0.2160</td>\n","      <td>0.05891</td>\n","      <td>0.4332</td>\n","      <td>1.2650</td>\n","      <td>2.844</td>\n","      <td>43.68</td>\n","      <td>0.00488</td>\n","      <td>0.01952</td>\n","      <td>0.02219</td>\n","      <td>0.00923</td>\n","      <td>0.01535</td>\n","      <td>0.00237</td>\n","      <td>19.47</td>\n","      <td>31.68</td>\n","      <td>129.7</td>\n","      <td>1175.0</td>\n","      <td>0.1395</td>\n","      <td>0.3055</td>\n","      <td>0.2992</td>\n","      <td>0.1312</td>\n","      <td>0.3480</td>\n","      <td>0.07619</td>\n","      <td>1.2</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>194 rows × 33 columns</p>\n","</div>"],"text/plain":["      0      1      2       3       4   ...      28      29       30   31  32\n","0    1.0  16.13  20.68  108.10   798.8  ...  0.2073  0.3706  0.11420  3.0   1\n","1    0.0  15.34  14.26  102.50   704.4  ...  0.2393  0.4667  0.09946  1.3   1\n","2    1.0  21.16  23.04  137.20  1404.0  ...  0.2009  0.2822  0.07526  4.0   1\n","3    0.0  19.07  24.81  128.30  1104.0  ...  0.2493  0.4670  0.10380  2.3   1\n","4    0.0  18.65  17.60  123.70  1076.0  ...  0.2378  0.3799  0.09185  1.8   1\n","..   ...    ...    ...     ...     ...  ...     ...     ...      ...  ...  ..\n","189  0.0  15.78  17.89  103.60   781.0  ...  0.1810  0.3792  0.10480  1.4   5\n","190  0.0  14.68  20.13   94.74   684.5  ...  0.1609  0.3029  0.08216  1.1   5\n","191  2.0  11.84  18.70   77.93   440.6  ...  0.1546  0.4761  0.14020  3.0   5\n","192  0.0  13.11  15.56   87.21   530.2  ...  0.1986  0.3147  0.14050  1.5   5\n","193  0.0  16.16  21.54  106.20   809.8  ...  0.1312  0.3480  0.07619  1.2   5\n","\n","[194 rows x 33 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"fyVy2BE1oivc","executionInfo":{"status":"ok","timestamp":1609211979061,"user_tz":300,"elapsed":822,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["X = data.to_numpy()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcN7z4NIosYt","executionInfo":{"status":"ok","timestamp":1609211979894,"user_tz":300,"elapsed":588,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"b4400c3a-6b96-432a-a08f-a9c1697aea40"},"source":["X.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(194, 33)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"igGQ6avOovJ4","executionInfo":{"status":"ok","timestamp":1609211995862,"user_tz":300,"elapsed":654,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["y = X[:,-1]\n","X = X[:,0:-1]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqS2UFJYpvKh","executionInfo":{"status":"ok","timestamp":1609211997128,"user_tz":300,"elapsed":574,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"61bf90c1-ca5f-472c-ccb3-d75f60216cdb"},"source":["X.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(194, 32)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xw0ss3-Jo1cG","executionInfo":{"status":"ok","timestamp":1609212025641,"user_tz":300,"elapsed":523,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"710080b8-391a-4f30-9042-a78fef0645c5"},"source":["print(max(y))\n","print(min(y))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[1.]\n","[0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EDJqxy1spUvs","executionInfo":{"status":"ok","timestamp":1609212006191,"user_tz":300,"elapsed":598,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["y = (y-1)/4"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"BmELQl5Dq_lP","executionInfo":{"status":"ok","timestamp":1609212011933,"user_tz":300,"elapsed":688,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["y = np.float64(y)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRMk2hn8G350","executionInfo":{"status":"ok","timestamp":1609212022073,"user_tz":300,"elapsed":551,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["y = y.reshape((194,1))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPzDatdorbgf","executionInfo":{"status":"ok","timestamp":1609212023908,"user_tz":300,"elapsed":655,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["X = np.float64(X)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"TjUicwGKN_t0"},"source":["from sklearn import preprocessing\n","X = preprocessing.scale(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKei5jZFOiIn"},"source":["from scipy.spatial import distance\n","\n","distances = distance.cdist(X, X, 'euclidean')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"7N9O3gaWOiZI","executionInfo":{"status":"ok","timestamp":1606966747647,"user_tz":300,"elapsed":29903,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"87453c05-4cff-494c-c8ef-46337e104521"},"source":["import matplotlib.pyplot as plt\n","\n","_ = plt.hist(distances, bins='auto')  # arguments are passed to np.histogram\n","\n","plt.title(\"Histogram with 'auto' bins\")\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Qy7U5VrTOsjg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-YvWgZbauj3","executionInfo":{"status":"ok","timestamp":1609212041725,"user_tz":300,"elapsed":766,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_I0nwG23ivJp","executionInfo":{"status":"ok","timestamp":1609219697763,"user_tz":300,"elapsed":7346753,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"3c234209-51e7-4200-d419-c9c2da67664e"},"source":["for i in range(24):\n","\n","    beta = 1 + np.random.sample()*19.9\n","    gamma = np.random.sample()*0.1\n","    learning_rate = 0.000000099 + np.random.sample()*0.0009999\n","    alpha = np.random.sample()\n","    dim_x = np.random.choice([1024, 512, 256])\n","    dim_x = int(dim_x)\n","    num_eig = np.random.choice([int(dim_x/8), int(dim_x/16), int(dim_x/32)])\n","    num_eig = int(num_eig)\n","    print('------------', i+1, 'beta=', beta, 'gamma=', gamma, 'learning_rate=', learning_rate, 'alpha=', alpha, 'dim_x=', dim_x, 'num_eig=', num_eig)\n","\n","    MAE = []\n","\n","    dim_y = 5\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    for i in range(5): \n","        X_train, y_train = shuffle(X_train, y_train)\n","        qmr2.set_rho(qmr.get_rho())\n","        # Train model with SGD\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","        qmr2.layers[0].trainable = True\n","\n","        def loss(y_true, y_pred):\n","            return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha * y_pred[:, 1:2]\n","\n","        qmr2.compile(optimizer, loss=loss)\n","        qmr2.set_rho(qmr.get_rho())\n","        early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                    min_delta=0,\n","                                    patience=5,\n","                                    verbose=1,\n","                                    mode=\"auto\",\n","                                    restore_best_weights=True,\n","                                    )\n","\n","        qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","        out = qmr2.predict(X_test, batch_size = 4)\n","        y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","        MAE.append(mean_absolute_error(np.rint(y_test*4)+1, np.rint(y_pred*4)+1))\n","\n","    print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["------------ 1 beta= 3.485283112544436 gamma= 0.04263201501489349 learning_rate= 0.0004012384669550905 alpha= 0.5836978880442146 dim_x= 1024 num_eig= 128\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00024: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00027: early stopping\n","---------------------mean MAE = 1.1593220338983052  , std = 0.02299094909533983\n","------------ 2 beta= 14.063243796091513 gamma= 0.03335736290706165 learning_rate= 0.0006208949699917043 alpha= 0.37283404818847543 dim_x= 256 num_eig= 8\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","---------------------mean MAE = 1.1559322033898305  , std = 0.03619348560010611\n","------------ 3 beta= 19.02237938199269 gamma= 0.0009559124245880791 learning_rate= 0.00014960037514784533 alpha= 0.0382808640323028 dim_x= 512 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","---------------------mean MAE = 1.1220338983050848  , std = 0.019765938626594277\n","------------ 4 beta= 19.131909749593117 gamma= 0.09787532645459118 learning_rate= 0.00016929783680138738 alpha= 0.613460034828178 dim_x= 1024 num_eig= 32\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","---------------------mean MAE = 1.1627118644067795  , std = 0.05207556439232956\n","------------ 5 beta= 15.304127389516681 gamma= 0.06827394140616228 learning_rate= 0.0008440905829979581 alpha= 0.15451353576249593 dim_x= 1024 num_eig= 64\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","---------------------mean MAE = 1.135593220338983  , std = 0.04010901547864145\n","------------ 6 beta= 1.822092924122034 gamma= 0.07089501385410767 learning_rate= 0.0006876408220091798 alpha= 0.2724533823099694 dim_x= 256 num_eig= 8\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00024: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","---------------------mean MAE = 1.1966101694915254  , std = 0.0723869712002123\n","------------ 7 beta= 12.911184657455234 gamma= 0.01951014982297854 learning_rate= 0.0008379192594502215 alpha= 0.6032765175354435 dim_x= 512 num_eig= 32\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","---------------------mean MAE = 1.1762711864406779  , std = 0.04497118359803933\n","------------ 8 beta= 19.529602022256984 gamma= 0.029814102284031786 learning_rate= 0.0009925399844235236 alpha= 0.5855821069140444 dim_x= 1024 num_eig= 128\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","---------------------mean MAE = 1.1559322033898305  , std = 0.05402500830681095\n","------------ 9 beta= 14.975748784325623 gamma= 0.08177139987559676 learning_rate= 0.000894276185642641 alpha= 0.7722115278744222 dim_x= 1024 num_eig= 128\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","---------------------mean MAE = 1.1559322033898305  , std = 0.022485591799019673\n","------------ 10 beta= 3.8473527292409604 gamma= 0.012659571841288209 learning_rate= 9.321189339445921e-05 alpha= 0.22286960717604787 dim_x= 1024 num_eig= 32\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","---------------------mean MAE = 1.210169491525424  , std = 0.013559322033898369\n","------------ 11 beta= 12.086300039178376 gamma= 0.09652090814471385 learning_rate= 0.0005522317432089346 alpha= 0.5880102483920421 dim_x= 512 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","---------------------mean MAE = 1.1694915254237288  , std = 0.04287834115482544\n","------------ 12 beta= 16.580130369412174 gamma= 0.03584792930342571 learning_rate= 0.0003087383877330444 alpha= 0.4644265869429812 dim_x= 256 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","---------------------mean MAE = 1.1661016949152543  , std = 0.016606710120563875\n","------------ 13 beta= 1.4903701202599673 gamma= 0.06756775917724626 learning_rate= 0.0005485489063753015 alpha= 0.24896913168508494 dim_x= 256 num_eig= 8\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00025: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","---------------------mean MAE = 1.1593220338983052  , std = 0.025367168723891064\n","------------ 14 beta= 13.981960291682809 gamma= 0.06917159984627078 learning_rate= 0.0007157110046886594 alpha= 0.942088073057135 dim_x= 512 num_eig= 64\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00030: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00032: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","---------------------mean MAE = 1.159322033898305  , std = 0.027539113236054093\n","------------ 15 beta= 1.8402232889676595 gamma= 0.05840877840129213 learning_rate= 0.0003083740968284402 alpha= 0.3151632906444283 dim_x= 1024 num_eig= 32\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n","---------------------mean MAE = 1.2  , std = 0.06287198979997086\n","------------ 16 beta= 13.692199774187534 gamma= 0.061484925062716016 learning_rate= 0.0005405454239923996 alpha= 0.9234975858322619 dim_x= 256 num_eig= 32\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00024: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00028: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00044: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","---------------------mean MAE = 1.1728813559322036  , std = 0.016606710120563875\n","------------ 17 beta= 7.3564904613692965 gamma= 0.05134512447844303 learning_rate= 0.00012378009227286213 alpha= 0.46128223066585705 dim_x= 512 num_eig= 32\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","---------------------mean MAE = 1.111864406779661  , std = 0.04367491093805132\n","------------ 18 beta= 14.108839790005447 gamma= 0.09269140257578033 learning_rate= 0.00016612496038613086 alpha= 0.6921337436772113 dim_x= 512 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","---------------------mean MAE = 1.1593220338983052  , std = 0.02299094909533983\n","------------ 19 beta= 4.490180085282056 gamma= 0.03433293337855183 learning_rate= 0.0005295371755662833 alpha= 0.12073385507599899 dim_x= 512 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00016: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","---------------------mean MAE = 1.1593220338983052  , std = 0.07158885451506057\n","------------ 20 beta= 7.82894358990052 gamma= 0.04800523629167719 learning_rate= 0.00011812845818613254 alpha= 0.14635570226796746 dim_x= 1024 num_eig= 128\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","---------------------mean MAE = 1.223728813559322  , std = 0.06377928041432805\n","------------ 21 beta= 8.919944289966605 gamma= 0.08761853809591352 learning_rate= 0.0009055532036558977 alpha= 0.3594412415929621 dim_x= 512 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","---------------------mean MAE = 1.2135593220338983  , std = 0.029551857244343567\n","------------ 22 beta= 5.906720951455647 gamma= 0.008701435051696727 learning_rate= 0.0006384801756040549 alpha= 0.582269545231408 dim_x= 256 num_eig= 8\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00016: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","---------------------mean MAE = 1.1796610169491526  , std = 0.03953187725318853\n","------------ 23 beta= 10.703857834066227 gamma= 0.016708332209812105 learning_rate= 0.0006474812177315811 alpha= 0.3438182503103655 dim_x= 512 num_eig= 16\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","---------------------mean MAE = 1.1830508474576271  , std = 0.04721487551587839\n","------------ 24 beta= 20.83175534366888 gamma= 0.0944324027415574 learning_rate= 0.0005229921834870072 alpha= 0.3797204487896024 dim_x= 512 num_eig= 64\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","---------------------mean MAE = 1.1661016949152543  , std = 0.027118644067796616\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mSPBnkaXzKZP"},"source":["# Ahora los experimentos finales, con los mejores parametros para MSE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZ63q1VXzMQH","executionInfo":{"status":"ok","timestamp":1607539150478,"user_tz":300,"elapsed":166355,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"e4f0a1ae-f726-4657-a871-cbfa1102f109"},"source":["beta= 11.168578686120808 \n","gamma= 0.019782636050873624 \n","learning_rate= 0.0008736519215542466 \n","alpha= 0.383147331982576 \n","dim_x= 512 \n","num_eig= 32\n","\n","#beta= 14.937963660171226 \n","#gamma= 0.02192016019576171 \n","#learning_rate= 0.0003769575135508885 \n","#alpha= 0.45844374183474923 \n","#dim_x= 256 \n","#num_eig= 32\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","---------------------mean MAE = 0.9262711864406781  , std = 0.0849615895774877\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yIpe6bB-7pRz","executionInfo":{"status":"ok","timestamp":1607539456292,"user_tz":300,"elapsed":304351,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"88821cd4-9bcd-4f16-cd94-0daf2291b1ca"},"source":["beta= 11.168578686120808 \n","gamma= 0.019782636050873624 \n","learning_rate= 0.0008736519215542466 \n","alpha= 0.383147331982576 \n","dim_x= 512 \n","num_eig= 32\n","\n","#beta= 14.937963660171226 \n","#gamma= 0.02192016019576171 \n","#learning_rate= 0.0003769575135508885 \n","#alpha= 0.45844374183474923 \n","#dim_x= 256 \n","#num_eig= 32\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.MAE(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00042: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00037: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00032: early stopping\n","---------------------mean MAE = 0.951639344262295  , std = 0.09466769558837893\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDC9Vsry9yD1","executionInfo":{"status":"ok","timestamp":1607540011499,"user_tz":300,"elapsed":140029,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"4e057826-0bb7-46c9-b1dd-dcf30a548cf9"},"source":["beta= 11.168578686120808 \n","gamma= 0.019782636050873624 \n","learning_rate= 0.0008736519215542466 \n","alpha= 0.383147331982576 \n","dim_x= 512 \n","num_eig= 32\n","\n","#beta= 14.937963660171226 \n","#gamma= 0.02192016019576171 \n","#learning_rate= 0.0003769575135508885 \n","#alpha= 0.45844374183474923 \n","#dim_x= 256 \n","#num_eig= 32\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        h = tf.keras.losses.Huber()\n","        return h(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00034: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00046: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00042: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00033: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00047: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00033: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00025: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00025: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00051: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00027: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00026: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00029: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00026: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00049: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","---------------------mean MAE = 0.9819672131147541  , std = 0.10761143234279548\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"45hPUeB8-M3Y"},"source":["# Ahora los experimentos finales, con los mejores parametros para MAE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8tRlGLQ-O0G","executionInfo":{"status":"ok","timestamp":1607569014445,"user_tz":300,"elapsed":643145,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"c6785b78-705e-443f-8b91-ecdd9458d466"},"source":["beta= 17.81915647088741 \n","gamma= 0.019782636050873624 \n","learning_rate= 6.701501049808681e-05 \n","alpha= 0.48092427920298797 \n","dim_x= 512 \n","num_eig= 32\n","\n","#beta= 4.526095308003731 \n","#gamma= 0.026826101784219892 \n","#learning_rate= 0.0006221125931396382 \n","#alpha= 0.9805380719114533 \n","#dim_x= 1024 \n","#num_eig= 64\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00013: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00016: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00025: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","---------------------mean MAE = 0.9330508474576271  , std = 0.09802341294700949\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrDiaRMuitLj","executionInfo":{"status":"ok","timestamp":1607570884527,"user_tz":300,"elapsed":1870055,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"85ce62de-beab-4623-ce9f-18c096900f88"},"source":["beta= 4.526095308003731 \n","gamma= 0.026826101784219892 \n","learning_rate= 0.0006221125931396382 \n","alpha= 0.9805380719114533 \n","dim_x= 1024 \n","num_eig= 64\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","---------------------mean MAE = 0.8898305084745763  , std = 0.07739288174122627\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39WM7Lgd-O2u","executionInfo":{"status":"ok","timestamp":1607572229346,"user_tz":300,"elapsed":3214855,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"1b6b5049-1c2c-484d-82c1-50efe9a7b2f3"},"source":["beta= 17.81915647088741 \n","gamma= 0.019782636050873624 \n","learning_rate= 6.701501049808681e-05 \n","alpha= 0.48092427920298797 \n","dim_x= 512 \n","num_eig= 32\n","\n","#beta= 4.526095308003731 \n","#gamma= 0.026826101784219892 \n","#learning_rate= 0.0006221125931396382 \n","#alpha= 0.9805380719114533 \n","#dim_x= 1024 \n","#num_eig= 64\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.MAE(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00026: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00030: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00027: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00028: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00047: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00046: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00047: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00031: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00028: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00032: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00034: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00027: early stopping\n","---------------------mean MAE = 0.9581967213114755  , std = 0.09090234149531477\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Xmhr11pi0FK","executionInfo":{"status":"ok","timestamp":1607578714919,"user_tz":300,"elapsed":9700421,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"6e85c525-d709-4d93-a19e-66c5fe0e8308"},"source":["beta= 4.526095308003731 \n","gamma= 0.026826101784219892 \n","learning_rate= 0.0006221125931396382 \n","alpha= 0.9805380719114533 \n","dim_x= 1024 \n","num_eig= 64\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.MAE(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00048: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00044: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00037: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00035: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00047: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00028: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00049: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00031: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00025: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00033: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00043: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00011: early stopping\n","---------------------mean MAE = 1.0344262295081967  , std = 0.09430148864439118\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJB3Aa2s-O6D","executionInfo":{"status":"ok","timestamp":1607581068750,"user_tz":300,"elapsed":12054246,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"f67d4120-d09d-47d9-a132-712059df7bd9"},"source":["beta= 17.81915647088741 \n","gamma= 0.019782636050873624 \n","learning_rate= 6.701501049808681e-05 \n","alpha= 0.48092427920298797 \n","dim_x= 512 \n","num_eig= 32\n","\n","#beta= 4.526095308003731 \n","#gamma= 0.026826101784219892 \n","#learning_rate= 0.0006221125931396382 \n","#alpha= 0.9805380719114533 \n","#dim_x= 1024 \n","#num_eig= 64\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        h = tf.keras.losses.Huber()\n","        return h(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00053: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","34/34 [==============================] - 0s 1ms/step\n","---------------------mean MAE = 0.9983606557377047  , std = 0.10275694389649064\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuCRKZ7Ai6jf","executionInfo":{"status":"ok","timestamp":1607590056289,"user_tz":300,"elapsed":21041779,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"fe81641e-a6c2-43bd-d366-19aaa047a860"},"source":["beta= 4.526095308003731 \n","gamma= 0.026826101784219892 \n","learning_rate= 0.0006221125931396382 \n","alpha= 0.9805380719114533 \n","dim_x= 1024 \n","num_eig= 64\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        h = tf.keras.losses.Huber()\n","        return h(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00052: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00051: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00030: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00042: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00055: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00036: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00038: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00036: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00053: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00055: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00039: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00057: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00057: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00050: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00042: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00036: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00055: early stopping\n","34/34 [==============================] - 0s 3ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00038: early stopping\n","---------------------mean MAE = 1.0032786885245901  , std = 0.07342359238215966\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v270gosV-PLC"},"source":["# Ahora los experimentos finales, con los mejores parametros para HUBER"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4geiaDXc-RqV","executionInfo":{"status":"ok","timestamp":1607542163393,"user_tz":300,"elapsed":174980,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"757d453d-3e52-4b13-dad8-0142b10412b8"},"source":["beta= 7.902870743663927 \n","gamma= 0.019782636050873624 \n","learning_rate= 0.00017466660484643585 \n","alpha= 0.34917795264541507 \n","dim_x= 512 \n","num_eig= 64\n","\n","#beta= 18.357737577708882 \n","#gamma= 0.09416500056019565 \n","#learning_rate= 0.00044636852080991385 \n","#alpha= 0.8888784573520224 \n","#dim_x= 512 \n","#num_eig= 32\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.mean_squared_error(y_true, y_pred[:,0:1]) + alpha * y_pred[:, 1:2]\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 4, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 4)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00008: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00010: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00007: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00006: early stopping\n","---------------------mean MAE = 0.9377049180327868  , std = 0.06445771557815574\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"al4siEsF-Rs2","executionInfo":{"status":"ok","timestamp":1607542575266,"user_tz":300,"elapsed":586827,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"0d7fc450-8096-49fb-c8c6-e05f1f3ccf2a"},"source":["beta= 7.902870743663927 \n","gamma= 0.019782636050873624 \n","learning_rate= 0.00017466660484643585 \n","alpha= 0.34917795264541507 \n","dim_x= 512 \n","num_eig= 64\n","\n","#beta= 18.357737577708882 \n","#gamma= 0.09416500056019565 \n","#learning_rate= 0.00044636852080991385 \n","#alpha= 0.8888784573520224 \n","#dim_x= 512 \n","#num_eig= 32\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        return tf.keras.losses.MAE(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 32, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 32)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00016: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00026: early stopping\n","WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f167c090c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","WARNING:tensorflow:6 out of the last 25 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a74b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00016: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a41d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e118378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00016: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a2b8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a265268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00009: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16d0137950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a7532f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e7308c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00022: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f167c1a0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f167c087378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00015: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e6f9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a6c4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00018: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e506730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00014: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f167c0571e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e4f1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00012: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a35a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","---------------------mean MAE = 0.9557377049180328  , std = 0.10446881289412999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WY9uaKxA-Rvb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607543657885,"user_tz":300,"elapsed":1669438,"user":{"displayName":"Santiago Toledo Cortés","photoUrl":"","userId":"12101590182054542603"}},"outputId":"3c5e2687-4fb4-4f33-9625-6f6f29f67a05"},"source":["beta= 7.902870743663927 \n","gamma= 0.019782636050873624 \n","learning_rate= 0.00017466660484643585 \n","alpha= 0.34917795264541507 \n","dim_x= 512 \n","num_eig= 64\n","\n","#beta= 18.357737577708882 \n","#gamma= 0.09416500056019565 \n","#learning_rate= 0.00044636852080991385 \n","#alpha= 0.8888784573520224 \n","#dim_x= 512 \n","#num_eig= 32\n","\n","dim_y = 5\n","MAE = []\n","for i in range(20): \n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.31)\n","\n","    fm_y = layers.QFeatureMapSmp(dim=dim_y, beta=beta)\n","    fm_x = layers.QFeatureMapRFF(32, dim=dim_x, gamma=gamma, random_state=1)\n","    qmr2 = models.QMRegressorSGD(input_dim=32, dim_x=dim_x, num_eig=num_eig, dim_y=dim_y, gamma=gamma, random_state=17)\n","\n","    # for initialize weights\n","\n","    qmr = models.QMRegressor(fm_x=fm_x, fm_y=fm_y, dim_x=dim_x, dim_y=dim_y)\n","    qmr.compile()\n","    qmr.fit(X_train, y_train, epochs=1, batch_size = 4)\n","\n","    qmr2.set_rho(qmr.get_rho())\n","    # Train model with SGD\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    qmr2.layers[0].trainable = True\n","\n","    def loss(y_true, y_pred):\n","        h = tf.keras.losses.Huber()\n","        return h(y_true, y_pred[:,0:1]) + alpha * tf.math.sqrt(y_pred[:, 1:2])\n","\n","    qmr2.compile(optimizer, loss=loss)\n","    qmr2.set_rho(qmr.get_rho())\n","    early_stop = EarlyStopping( monitor=\"val_loss\",\n","                                min_delta=0,\n","                                patience=5,\n","                                verbose=1,\n","                                mode=\"auto\",\n","                                restore_best_weights=True,\n","                                )\n","\n","    qmr2.fit(X_train, y_train, epochs=60, validation_split = 0.2, batch_size = 32, callbacks = early_stop, verbose = 0)\n","\n","    out = qmr2.predict(X_test, batch_size = 32)\n","    y_pred, std = out[:, 0], np.sqrt(out[:, 1])\n","\n","    MAE.append(mean_absolute_error(np.rint(y_test*4), np.rint(y_pred*4)))\n","\n","print('---------------------mean MAE =', np.mean(MAE), ' , std =', np.std(MAE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e109ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16d02286a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e16e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e16eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00050: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e76b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00044: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e3fe0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00046: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e68fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a7091e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16d962b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a379400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00041: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e515158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00057: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a74b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e0618c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a426d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00049: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a7d6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00038: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e5228c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165a63bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f167c3f7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00044: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e32a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","34/34 [==============================] - 0s 1ms/step\n","Restoring model weights from the end of the best epoch.\n","Epoch 00049: early stopping\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f165e6e0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","---------------------mean MAE = 0.9385245901639344  , std = 0.09401249866873694\n"],"name":"stdout"}]}]}